{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4pA1GqRUoDs"
      },
      "source": [
        "# 캔들차트 데이터 생성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53vk9JlnVHse"
      },
      "source": [
        "참고 : https://dataplay.tistory.com/37?category=845492"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwWkUvpy8GO_"
      },
      "source": [
        "참고코드 : https://colab.research.google.com/drive/1WXG3cohwO6_0mbmB9CdT37cc1jfE2Zon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecKTs5RpGkmA",
        "outputId": "32c460f6-7133-4f9d-c939-66ee6e57cdc7"
      },
      "source": [
        "!pip install mpl_finance\n",
        "!pip install -U finance_datareader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mpl_finance\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/de/8169ea4403d6cb8322e74cc48b6834d1dfbed81931d17f1f26b2140160d8/mpl_finance-0.10.1-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mpl_finance) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpl_finance) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpl_finance) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpl_finance) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpl_finance) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpl_finance) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->mpl_finance) (1.15.0)\n",
            "Installing collected packages: mpl-finance\n",
            "Successfully installed mpl-finance-0.10.1\n",
            "Collecting finance_datareader\n",
            "  Downloading https://files.pythonhosted.org/packages/83/5e/54306e72b5ff5d5ec6cc9f32cdf19602237f9bb70d64efcd527338388be3/finance_datareader-0.9.31-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from finance_datareader) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from finance_datareader) (2.23.0)\n",
            "Collecting requests-file\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.7/dist-packages (from finance_datareader) (4.2.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from finance_datareader) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance_datareader) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance_datareader) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance_datareader) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance_datareader) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance_datareader) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance_datareader) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance_datareader) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from requests-file->finance_datareader) (1.15.0)\n",
            "Installing collected packages: requests-file, finance-datareader\n",
            "Successfully installed finance-datareader-0.9.31 requests-file-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tk5GAWQU5gV"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import FinanceDataReader as fdr\n",
        "\n",
        "from shutil import copyfile, move\n",
        "from mpl_finance import candlestick2_ochl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHRMT0S7YyQo"
      },
      "source": [
        "도지 코인 파일 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXv0Bbmd76x9"
      },
      "source": [
        "data =  fdr.DataReader(\"KS11\", '1979-01-01', '2021-06-18')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cWobfBz8FCc"
      },
      "source": [
        "data = data.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "wFYjoox_n0ok",
        "outputId": "2894dbf6-4b6e-4d36-9d29-52301d8fd47f"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Change</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1997-06-16</th>\n",
              "      <td>1249</td>\n",
              "      <td>1259</td>\n",
              "      <td>1227</td>\n",
              "      <td>1233</td>\n",
              "      <td>70480</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997-06-17</th>\n",
              "      <td>1233</td>\n",
              "      <td>1329</td>\n",
              "      <td>1215</td>\n",
              "      <td>1305</td>\n",
              "      <td>357930</td>\n",
              "      <td>0.058394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997-06-18</th>\n",
              "      <td>1322</td>\n",
              "      <td>1340</td>\n",
              "      <td>1279</td>\n",
              "      <td>1296</td>\n",
              "      <td>238420</td>\n",
              "      <td>-0.006897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997-06-19</th>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1263</td>\n",
              "      <td>1269</td>\n",
              "      <td>145140</td>\n",
              "      <td>-0.020833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997-06-20</th>\n",
              "      <td>1286</td>\n",
              "      <td>1286</td>\n",
              "      <td>1242</td>\n",
              "      <td>1251</td>\n",
              "      <td>150060</td>\n",
              "      <td>-0.014184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-14</th>\n",
              "      <td>80800</td>\n",
              "      <td>80900</td>\n",
              "      <td>80500</td>\n",
              "      <td>80500</td>\n",
              "      <td>10550078</td>\n",
              "      <td>-0.006173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-15</th>\n",
              "      <td>80900</td>\n",
              "      <td>81200</td>\n",
              "      <td>80600</td>\n",
              "      <td>80900</td>\n",
              "      <td>10075685</td>\n",
              "      <td>0.004969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-16</th>\n",
              "      <td>81500</td>\n",
              "      <td>81900</td>\n",
              "      <td>81100</td>\n",
              "      <td>81800</td>\n",
              "      <td>14999855</td>\n",
              "      <td>0.011125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-17</th>\n",
              "      <td>81100</td>\n",
              "      <td>81300</td>\n",
              "      <td>80700</td>\n",
              "      <td>80900</td>\n",
              "      <td>14007385</td>\n",
              "      <td>-0.011002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-18</th>\n",
              "      <td>81100</td>\n",
              "      <td>81100</td>\n",
              "      <td>80500</td>\n",
              "      <td>80500</td>\n",
              "      <td>14618173</td>\n",
              "      <td>-0.004944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Open   High    Low  Close    Volume    Change\n",
              "Date                                                      \n",
              "1997-06-16   1249   1259   1227   1233     70480       NaN\n",
              "1997-06-17   1233   1329   1215   1305    357930  0.058394\n",
              "1997-06-18   1322   1340   1279   1296    238420 -0.006897\n",
              "1997-06-19   1304   1304   1263   1269    145140 -0.020833\n",
              "1997-06-20   1286   1286   1242   1251    150060 -0.014184\n",
              "...           ...    ...    ...    ...       ...       ...\n",
              "2021-06-14  80800  80900  80500  80500  10550078 -0.006173\n",
              "2021-06-15  80900  81200  80600  80900  10075685  0.004969\n",
              "2021-06-16  81500  81900  81100  81800  14999855  0.011125\n",
              "2021-06-17  81100  81300  80700  80900  14007385 -0.011002\n",
              "2021-06-18  81100  81100  80500  80500  14618173 -0.004944\n",
              "\n",
              "[6000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "OX4MDmlcLRzV",
        "outputId": "f970ea19-45ad-4336-84f3-6a56dd39e228"
      },
      "source": [
        "plt.plot(data['Close'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f79d8fb8050>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ9bQXV7EziD"
      },
      "source": [
        "def ohlc2cs2(data, seq_len, dimension):\n",
        "    # python preprocess.py -m ohlc2cs -l 20 -i stockdatas/EWT_testing.csv -t testing\n",
        "    print(\"Converting olhc to candlestick\")\n",
        "    df = data\n",
        "    plt.style.use('dark_background')\n",
        "    figs = np.zeros((len(df)-1, dimension, dimension, 3))\n",
        "    labels = []\n",
        "    for i in range(0, len(df)-1):\n",
        "        # ohlc+volume\n",
        "        c = df.loc[i:i + int(seq_len) - 1, :]\n",
        "        c_ = df.loc[i:i + int(seq_len), :]\n",
        "        if len(c) == int(seq_len):\n",
        "            my_dpi = 96\n",
        "            fig = plt.figure(figsize=(dimension / my_dpi,\n",
        "                                      dimension / my_dpi), dpi=my_dpi)\n",
        "            ax1 = fig.add_subplot(1, 1, 1)\n",
        "            candlestick2_ochl(ax1, c['Open'], c['Close'], c['High'],\n",
        "                              c['Low'], width=1,\n",
        "                              colorup='#77d879', colordown='#db3f3f')\n",
        "            ax1.grid(False)\n",
        "            ax1.set_xticklabels([])\n",
        "            ax1.set_yticklabels([])\n",
        "            ax1.xaxis.set_visible(False)\n",
        "            ax1.yaxis.set_visible(False)\n",
        "            ax1.axis('off')\n",
        "\n",
        "            # create the second axis for the volume bar-plot\n",
        "            # Add a seconds axis for the volume overlay\n",
        "\n",
        "        starting = c_[\"Close\"].iloc[-2]\n",
        "        endvalue = c_[\"Close\"].iloc[-1]\n",
        "        if endvalue > starting :\n",
        "            label = 1\n",
        "        else :\n",
        "            label = 0\n",
        "        labels.append(label)\n",
        "\n",
        "        fig.canvas.draw()\n",
        "        fig_np = np.array(fig.canvas.renderer._renderer)\n",
        "        figs[i] = fig_np[:,:,:3]\n",
        "\n",
        "        plt.close(fig)\n",
        "        # normal length - end\n",
        "\n",
        "    print(\"Converting olhc to candlestik finished.\")\n",
        "    return figs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-WDQKFCE2Q-",
        "outputId": "3f955480-3606-40b9-b1a8-4d662d4f815b"
      },
      "source": [
        "inputs = data\n",
        "seq_len = 30\n",
        "dimension = 48\n",
        "\n",
        "figures, labels = ohlc2cs2(inputs, seq_len, dimension)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting olhc to candlestick\n",
            "Converting olhc to candlestik finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwryKR7IJE81",
        "outputId": "fd071379-fff6-438a-e423-375db5e019e7"
      },
      "source": [
        "#위 함수로 생성된 figures는 값의 범위가 0~255 이기 때문에 0~1로 맞춰주기 위해 255로 나눕니다.\n",
        "figures = figures/255.0\n",
        "print(np.shape(labels), np.shape(figures))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10363,) (10363, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-U75_0hp65I"
      },
      "source": [
        "데이터 제너레이팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDE80zOAJKtw"
      },
      "source": [
        "def single_stock_generator(chart, labels, batch_size) :\n",
        "    #output [chart, labels]\n",
        "    while True :\n",
        "        stock_batch = np.zeros(shape=(batch_size, dimension, dimension, 3))\n",
        "        label_batch = np.zeros(shape=(batch_size, ))\n",
        "        for i in range(batch_size) :\n",
        "            idx = np.random.randint(len(labels))\n",
        "            stock_batch[i] = chart[idx]\n",
        "            label_batch[i] = labels[idx]\n",
        "\n",
        "        yield stock_batch, label_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alQfZUPKJKrM"
      },
      "source": [
        "train_len = 6943\n",
        "batch_size = 16\n",
        "train_gen = single_stock_generator(figures[:train_len], labels[:train_len], batch_size)\n",
        "test_gen = single_stock_generator(figures[train_len:], labels[train_len:], batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc9n4_pAJKoz",
        "outputId": "3ebf4e47-89e2-4aa0-8ec8-dad8c47561de"
      },
      "source": [
        "tmp_data = next(train_gen)\n",
        "print(\"Chart image shape : \",np.shape(tmp_data[0]))\n",
        "print(\"Label shape :\",np.shape(tmp_data[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chart image shape :  (16, 48, 48, 3)\n",
            "Label shape : (16,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyziFTLVJKmi"
      },
      "source": [
        "# 만들어진 차트 이미지 중 하나를 예시로 그려보겠습니다.\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0wb73ra3Act",
        "outputId": "483abdf9-bb23-4ec7-9f56-64078af074db"
      },
      "source": [
        "len(tmp_data[0][0][:,:,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "WnHyOng6JKkS",
        "outputId": "0251d7a0-ffdd-42fa-a169-3bd0c67585ad"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(tmp_data[0][15][:,:,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C6p10cctvah"
      },
      "source": [
        "# 모듈, 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaF55R5XLAyf"
      },
      "source": [
        "# Keras의 Functional APi를 이용할 거라서 불러와줍니다.\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhMOxzKWxFf-"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyvxwSH9tyrS"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, classification_report, confusion_matrix, mean_squared_error\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "from pandas import get_dummies\n",
        "import xgboost as xgb\n",
        "import scipy\n",
        "import math\n",
        "import json\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import tqdm\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "from keras.optimizers import SGD\n",
        "from tqdm import tqdm_notebook\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Ny4wZnNLQP"
      },
      "source": [
        "# ANN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWdW6vAD2ViV"
      },
      "source": [
        "참고 코드 : https://colab.research.google.com/drive/1rIylR9RWEckndbyFNx1Wl_yUQZUF-wyI#scrollTo=70zNPAmbZcGh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcfK7Bqje2n-",
        "outputId": "0cf6fd72-df27-43fd-98bc-a3a5e67215b0"
      },
      "source": [
        "inputs = keras.Input(shape=(48, 48, 3))\n",
        "x = inputs\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "outputs = x\n",
        "\n",
        "ANN = keras.Model(inputs, outputs)\n",
        "ANN.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6912)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                221216    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 221,249\n",
            "Trainable params: 221,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwUI2JDURsTY",
        "outputId": "0c9ca6de-6abd-4d1b-d269-c114c0b1b8d8"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        y_ = ANN(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        y_= ANN(x_batch)\n",
        "        loss_value2 = loss_fn(y_batch, y_)\n",
        "        acc_value2 = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value2)\n",
        "        val_acc_avg(acc_value2)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "ANN_loss = float(format(val_loss_avg.result()))\n",
        "ANN_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69714 , Train acc: 0.51196\n",
            "Val_Loss: 0.696, Val_acc: 0.505\n",
            "Epoch 001: , Train Loss: 0.69696 , Train acc: 0.50842\n",
            "Val_Loss: 0.695, Val_acc: 0.509\n",
            "Epoch 002: , Train Loss: 0.69332 , Train acc: 0.51046\n",
            "Val_Loss: 0.702, Val_acc: 0.511\n",
            "Epoch 003: , Train Loss: 0.69659 , Train acc: 0.51142\n",
            "Val_Loss: 0.702, Val_acc: 0.511\n",
            "Epoch 004: , Train Loss: 0.69579 , Train acc: 0.51073\n",
            "Val_Loss: 0.697, Val_acc: 0.512\n",
            "Epoch 005: , Train Loss: 0.69746 , Train acc: 0.51116\n",
            "Val_Loss: 0.701, Val_acc: 0.511\n",
            "Epoch 006: , Train Loss: 0.69528 , Train acc: 0.51076\n",
            "Val_Loss: 0.701, Val_acc: 0.510\n",
            "Epoch 007: , Train Loss: 0.69356 , Train acc: 0.51082\n",
            "Val_Loss: 0.692, Val_acc: 0.511\n",
            "Epoch 008: , Train Loss: 0.69668 , Train acc: 0.51125\n",
            "Val_Loss: 0.693, Val_acc: 0.511\n",
            "Epoch 009: , Train Loss: 0.69552 , Train acc: 0.51182\n",
            "Val_Loss: 0.699, Val_acc: 0.512\n",
            "Epoch 010: , Train Loss: 0.69498 , Train acc: 0.51203\n",
            "Val_Loss: 0.696, Val_acc: 0.512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRj-rj3Dncc8",
        "outputId": "ec0c9472-b42e-4beb-e824-f8dff2dba5d1"
      },
      "source": [
        "ANN_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5120896100997925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spiP-T0gx7qZ"
      },
      "source": [
        "# 1D CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbg6L2dn9fJj",
        "outputId": "8ea63e5b-cf21-4e0a-e424-0a8e3af83364"
      },
      "source": [
        "inputs = keras.Input(shape=(48, 48, 3))\n",
        "x = inputs\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, padding=\"causal\",activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "outputs = x\n",
        "\n",
        "CNN1D = keras.Model(inputs, outputs)\n",
        "CNN1D.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 48, 48, 32)        512       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 73728)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 16)                1179664   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,180,193\n",
            "Trainable params: 1,180,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olS1wlkpyz3A",
        "outputId": "a27d7bfc-4f17-4c6f-c46f-e4cbf6e09e22"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        y_ = CNN1D(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        y_= CNN1D(x_batch)\n",
        "        loss_value2 = loss_fn(y_batch, y_)\n",
        "        acc_value2 = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value2)\n",
        "        val_acc_avg(acc_value2)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "CNN1D_loss = float(format(val_loss_avg.result()))\n",
        "CNN1D_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69347 , Train acc: 0.48677\n",
            "Val_Loss: 0.693, Val_acc: 0.496\n",
            "Epoch 001: , Train Loss: 0.69368 , Train acc: 0.49155\n",
            "Val_Loss: 0.694, Val_acc: 0.490\n",
            "Epoch 002: , Train Loss: 0.69332 , Train acc: 0.49082\n",
            "Val_Loss: 0.694, Val_acc: 0.492\n",
            "Epoch 003: , Train Loss: 0.69330 , Train acc: 0.49245\n",
            "Val_Loss: 0.694, Val_acc: 0.492\n",
            "Epoch 004: , Train Loss: 0.69325 , Train acc: 0.49369\n",
            "Val_Loss: 0.694, Val_acc: 0.493\n",
            "Epoch 005: , Train Loss: 0.69328 , Train acc: 0.49348\n",
            "Val_Loss: 0.694, Val_acc: 0.493\n",
            "Epoch 006: , Train Loss: 0.69298 , Train acc: 0.49375\n",
            "Val_Loss: 0.694, Val_acc: 0.495\n",
            "Epoch 007: , Train Loss: 0.69319 , Train acc: 0.49551\n",
            "Val_Loss: 0.695, Val_acc: 0.495\n",
            "Epoch 008: , Train Loss: 0.69311 , Train acc: 0.49535\n",
            "Val_Loss: 0.693, Val_acc: 0.496\n",
            "Epoch 009: , Train Loss: 0.69323 , Train acc: 0.49614\n",
            "Val_Loss: 0.694, Val_acc: 0.496\n",
            "Epoch 010: , Train Loss: 0.69336 , Train acc: 0.49594\n",
            "Val_Loss: 0.694, Val_acc: 0.496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ2fGoU9zlph",
        "outputId": "80ad3b99-2a15-42d4-bc64-5f348139cfab"
      },
      "source": [
        "CNN1D_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49559661746025085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zFU8OcvJnam"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Ln0Vf4J5xm"
      },
      "source": [
        "참고 논문 : Using Deep Learning Neural Networks and Candlestick chart Representation to Predict Stock Market\n",
        "https://arxiv.org/pdf/1903.12258.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fZ1KZKbMk6x"
      },
      "source": [
        "다음날 종가가 상승이냐 아니냐를 맞추는 binary classification 문제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r9oU4VTtc07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96df11a8-42da-49d1-ead4-73aa3755d75f"
      },
      "source": [
        "inputs = keras.Input(shape=(48, 48, 3))\n",
        "x = inputs\n",
        "x = layers.Conv2D(48, 3, activation='relu', padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "x = layers.Conv2D(96, 3, activation='relu', padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "outputs = x\n",
        "\n",
        "CNN = keras.Model(inputs, outputs)\n",
        "CNN.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 48, 48)        1344      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 48)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 24, 24, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 96)        41568     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 96)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 12, 12, 96)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 13824)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 13825     \n",
            "=================================================================\n",
            "Total params: 56,737\n",
            "Trainable params: 56,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux-IH5iAXR-1",
        "outputId": "14a6aa88-eb9b-435e-8e99-4df27bb05b36"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        y_ = CNN(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        y_= CNN(x_batch)\n",
        "        loss_value2 = loss_fn(y_batch, y_)\n",
        "        acc_value2 = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value2)\n",
        "        val_acc_avg(acc_value2)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "CNN_loss = float(format(val_loss_avg.result()))\n",
        "CNN_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69399 , Train acc: 0.48474\n",
            "Val_Loss: 0.696, Val_acc: 0.484\n",
            "Epoch 001: , Train Loss: 0.69400 , Train acc: 0.48308\n",
            "Val_Loss: 0.694, Val_acc: 0.486\n",
            "Epoch 002: , Train Loss: 0.69403 , Train acc: 0.48516\n",
            "Val_Loss: 0.695, Val_acc: 0.485\n",
            "Epoch 003: , Train Loss: 0.69469 , Train acc: 0.48453\n",
            "Val_Loss: 0.694, Val_acc: 0.484\n",
            "Epoch 004: , Train Loss: 0.69421 , Train acc: 0.48476\n",
            "Val_Loss: 0.697, Val_acc: 0.484\n",
            "Epoch 005: , Train Loss: 0.69422 , Train acc: 0.48365\n",
            "Val_Loss: 0.694, Val_acc: 0.484\n",
            "Epoch 006: , Train Loss: 0.69431 , Train acc: 0.48448\n",
            "Val_Loss: 0.696, Val_acc: 0.484\n",
            "Epoch 007: , Train Loss: 0.69366 , Train acc: 0.48441\n",
            "Val_Loss: 0.695, Val_acc: 0.485\n",
            "Epoch 008: , Train Loss: 0.69390 , Train acc: 0.48508\n",
            "Val_Loss: 0.695, Val_acc: 0.485\n",
            "Epoch 009: , Train Loss: 0.69387 , Train acc: 0.48562\n",
            "Val_Loss: 0.694, Val_acc: 0.486\n",
            "Epoch 010: , Train Loss: 0.69393 , Train acc: 0.48569\n",
            "Val_Loss: 0.695, Val_acc: 0.486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pmt8oDZ2Lxa"
      },
      "source": [
        "# GRU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IHXhdWI0WG"
      },
      "source": [
        "소스코드 : https://github.com/zutshianand/Stock-Price-Prediction/blob/master/main.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8c-rP8sQYRl",
        "outputId": "6cfd2532-6a78-4568-ed95-40795365a402"
      },
      "source": [
        "regressorGRU = Sequential()\n",
        "# First GRU layer with Dropout regularisation\n",
        "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(2304, 3), activation='tanh'))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=1))\n",
        "regressorGRU.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_1 (GRU)                  (None, 2304, 50)          8250      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2304, 1)           51        \n",
            "=================================================================\n",
            "Total params: 8,301\n",
            "Trainable params: 8,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR0wZZCjSCbd",
        "outputId": "a163a9e6-78c9-40f7-f4e2-da4feea5c9ee"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_= regressorGRU(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value)\n",
        "        val_acc_avg(acc_value)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "GRU_loss = float(format(val_loss_avg.result()))\n",
        "GRU_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69058 , Train acc: 0.48567\n",
            "Val_Loss: 8.266, Val_acc: 0.459\n",
            "Epoch 001: , Train Loss: 8.67652 , Train acc: 0.46412\n",
            "Val_Loss: 8.087, Val_acc: 0.470\n",
            "Epoch 002: , Train Loss: 11.56870 , Train acc: 0.46991\n",
            "Val_Loss: 8.052, Val_acc: 0.471\n",
            "Epoch 003: , Train Loss: 7.71246 , Train acc: 0.47261\n",
            "Val_Loss: 8.239, Val_acc: 0.473\n",
            "Epoch 004: , Train Loss: 9.64061 , Train acc: 0.47092\n",
            "Val_Loss: 8.052, Val_acc: 0.472\n",
            "Epoch 005: , Train Loss: 11.56870 , Train acc: 0.47234\n",
            "Val_Loss: 7.998, Val_acc: 0.473\n",
            "Epoch 006: , Train Loss: 9.64061 , Train acc: 0.47386\n",
            "Val_Loss: 7.927, Val_acc: 0.475\n",
            "Epoch 007: , Train Loss: 10.60467 , Train acc: 0.47561\n",
            "Val_Loss: 8.364, Val_acc: 0.475\n",
            "Epoch 008: , Train Loss: 6.74845 , Train acc: 0.47338\n",
            "Val_Loss: 7.748, Val_acc: 0.475\n",
            "Epoch 009: , Train Loss: 5.78435 , Train acc: 0.47608\n",
            "Val_Loss: 8.034, Val_acc: 0.476\n",
            "Epoch 010: , Train Loss: 7.71246 , Train acc: 0.47639\n",
            "Val_Loss: 7.909, Val_acc: 0.477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUWVpOXsSC4d",
        "outputId": "53aa133e-ea4a-45eb-cd38-b1269d00f262"
      },
      "source": [
        "GRU_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47687822580337524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPJIiThwVYSo"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfiA6NWYdGxJ"
      },
      "source": [
        "shape 확인 기존 48,48,3 -> 48,3으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlz42Mn1b0xI",
        "outputId": "541407ea-f41a-4833-8cf1-7320e0c1493c"
      },
      "source": [
        "inputs = keras.Input(shape=(2304, 3))\n",
        "x = inputs\n",
        "# First LSTM layer with Dropout regularisation\n",
        "x = layers.LSTM(units=32, return_sequences=True)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "# Second LSTM layer\n",
        "x = layers.LSTM(units=32, return_sequences=True)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "# Third LSTM layer\n",
        "x = layers.LSTM(units=32, return_sequences=True)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "# Fourth LSTM layer\n",
        "x = layers.LSTM(units=32, return_sequences=True)(x)\n",
        "x = layers.Dropout(rate=0.5)(x)\n",
        "# The output layer\n",
        "x = layers.Dense(1)(x)\n",
        "outputs = x\n",
        "\n",
        "LSTM = keras.Model(inputs, outputs)\n",
        "LSTM.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 2304, 3)]         0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 2304, 32)          4608      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2304, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 2304, 32)          8320      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 2304, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 2304, 32)          8320      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 2304, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 2304, 32)          8320      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2304, 32)          0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2304, 1)           33        \n",
            "=================================================================\n",
            "Total params: 29,601\n",
            "Trainable params: 29,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIhamLBPfzeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a73b1ec-a03f-4639-c7a7-58f2e58142a8"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_ = LSTM(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg.update_state(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_= LSTM(x_batch)\n",
        "        loss_value2 = loss_fn(y_batch, y_)\n",
        "        acc_value2 = acc_fn(y_batch, y_)\n",
        "        val_loss_avg.update_state(loss_value2)\n",
        "        val_acc_avg(acc_value2)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "LSTM_loss = float(format(val_loss_avg.result()))\n",
        "LSTM_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 7.76814 , Train acc: 0.48606\n",
            "Val_Loss: 8.070, Val_acc: 0.494\n",
            "Epoch 001: , Train Loss: 7.64123 , Train acc: 0.49421\n",
            "Val_Loss: 8.364, Val_acc: 0.495\n",
            "Epoch 002: , Train Loss: 7.78373 , Train acc: 0.49485\n",
            "Val_Loss: 7.962, Val_acc: 0.494\n",
            "Epoch 003: , Train Loss: 7.89728 , Train acc: 0.49304\n",
            "Val_Loss: 8.105, Val_acc: 0.492\n",
            "Epoch 004: , Train Loss: 7.70135 , Train acc: 0.49226\n",
            "Val_Loss: 8.132, Val_acc: 0.493\n",
            "Epoch 005: , Train Loss: 7.81267 , Train acc: 0.49259\n",
            "Val_Loss: 8.239, Val_acc: 0.492\n",
            "Epoch 006: , Train Loss: 7.67463 , Train acc: 0.49240\n",
            "Val_Loss: 8.025, Val_acc: 0.493\n",
            "Epoch 007: , Train Loss: 7.68799 , Train acc: 0.49295\n",
            "Val_Loss: 8.266, Val_acc: 0.493\n",
            "Epoch 008: , Train Loss: 7.85275 , Train acc: 0.49252\n",
            "Val_Loss: 8.293, Val_acc: 0.492\n",
            "Epoch 009: , Train Loss: 7.89727 , Train acc: 0.49192\n",
            "Val_Loss: 8.302, Val_acc: 0.491\n",
            "Epoch 010: , Train Loss: 7.82380 , Train acc: 0.49085\n",
            "Val_Loss: 7.864, Val_acc: 0.491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXMGmdwxfq95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297ae1a1-ffd1-427e-d06e-769acee793d1"
      },
      "source": [
        "LSTM_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4910687804222107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ9ZdVpZVYsj"
      },
      "source": [
        "# BLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFFsx3gMF8BD"
      },
      "source": [
        "소스코드 : https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSLEtsxLzZKV"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ox8QPNE0m-",
        "outputId": "18f3e83f-a0ca-4212-fe6d-33e1455974cc"
      },
      "source": [
        "BL = Sequential()\n",
        "BL.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(2304, 3)))\n",
        "BL.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "BL.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_2 (Bidirection (None, 2304, 40)          3840      \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 2304, 1)           41        \n",
            "=================================================================\n",
            "Total params: 3,881\n",
            "Trainable params: 3,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDCaoOlvG2SW",
        "outputId": "f3dcfae2-dd20-4951-c1d2-36f1046e68f1"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_ = BL(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_= BL(x_batch)\n",
        "        loss_value2 = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value2)\n",
        "        val_acc_avg(acc_value)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "BLSTM_loss = float(format(val_loss_avg.result()))\n",
        "BLSTM_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.70747 , Train acc: 0.51776\n",
            "Val_Loss: 0.699, Val_acc: 0.513\n",
            "Epoch 001: , Train Loss: 0.71378 , Train acc: 0.50891\n",
            "Val_Loss: 0.697, Val_acc: 0.507\n",
            "Epoch 002: , Train Loss: 0.70835 , Train acc: 0.50824\n",
            "Val_Loss: 0.700, Val_acc: 0.509\n",
            "Epoch 003: , Train Loss: 0.70752 , Train acc: 0.51000\n",
            "Val_Loss: 0.698, Val_acc: 0.511\n",
            "Epoch 004: , Train Loss: 0.71164 , Train acc: 0.50994\n",
            "Val_Loss: 0.697, Val_acc: 0.510\n",
            "Epoch 005: , Train Loss: 0.70796 , Train acc: 0.51039\n",
            "Val_Loss: 0.703, Val_acc: 0.510\n",
            "Epoch 006: , Train Loss: 0.71098 , Train acc: 0.51012\n",
            "Val_Loss: 0.696, Val_acc: 0.510\n",
            "Epoch 007: , Train Loss: 0.71153 , Train acc: 0.50948\n",
            "Val_Loss: 0.698, Val_acc: 0.510\n",
            "Epoch 008: , Train Loss: 0.71076 , Train acc: 0.50965\n",
            "Val_Loss: 0.705, Val_acc: 0.509\n",
            "Epoch 009: , Train Loss: 0.70988 , Train acc: 0.50899\n",
            "Val_Loss: 0.704, Val_acc: 0.509\n",
            "Epoch 010: , Train Loss: 0.71021 , Train acc: 0.50890\n",
            "Val_Loss: 0.705, Val_acc: 0.509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhbWZBG0Hiqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a444e1-4da7-4c87-fcfd-9fa736a46134"
      },
      "source": [
        "BLSTM_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5086075663566589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSyqI4ihsc71"
      },
      "source": [
        "# Convlstm2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlGrIGES4uxg"
      },
      "source": [
        "참고 : https://deep-deep-deep.tistory.com/32 [딥딥딥]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pApNoPKsFJw_"
      },
      "source": [
        "소스 코드 : https://keras.io/examples/vision/conv_lstm/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4dYYXR05h9H"
      },
      "source": [
        "CNN 관련 : http://taewan.kim/post/cnn/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHP8ez-ggauf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5OZVgG38_hA",
        "outputId": "b22d3aee-baec-48be-e0ee-afda981c6c7f"
      },
      "source": [
        "seq = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(\n",
        "            shape=(48, 48, 3, 1)\n",
        "        ),  # Variable-length sequence of 40x40x1 frames\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv3D(\n",
        "            filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22gQTfBA9o4m",
        "outputId": "d13049a0-0174-46d4-e677-b136e9067e4b"
      },
      "source": [
        "seq.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 48, 48, 3, 40)     59200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 3, 40)     160       \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 48, 48, 3, 1)      1081      \n",
            "=================================================================\n",
            "Total params: 60,441\n",
            "Trainable params: 60,361\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bziRFm7-9n_P",
        "outputId": "1e1a433e-73f9-485e-8c4c-d5bd1734b7a7"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        x_batch = x_batch.reshape(16, 48, 48, 3, 1)\n",
        "        y_ = seq(x_batch)[0]\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        x_batch = x_batch.reshape(16, 48, 48, 3, 1)\n",
        "        y_= seq(x_batch)[0]\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value)\n",
        "        val_acc_avg(acc_value)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "Convlstm2D_loss = float(format(val_loss_avg.result()))\n",
        "Convlstm2D_acc = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69316 , Train acc: 0.49874\n",
            "Val_Loss: 0.693, Val_acc: 0.501\n",
            "Epoch 001: , Train Loss: 0.69316 , Train acc: 0.49974\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 002: , Train Loss: 0.69316 , Train acc: 0.49844\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 003: , Train Loss: 0.69316 , Train acc: 0.49784\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 004: , Train Loss: 0.69316 , Train acc: 0.49786\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 005: , Train Loss: 0.69316 , Train acc: 0.49780\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 006: , Train Loss: 0.69316 , Train acc: 0.49793\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 007: , Train Loss: 0.69316 , Train acc: 0.49777\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 008: , Train Loss: 0.69316 , Train acc: 0.49776\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 009: , Train Loss: 0.69316 , Train acc: 0.49795\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n",
            "Epoch 010: , Train Loss: 0.69316 , Train acc: 0.49807\n",
            "Val_Loss: 0.693, Val_acc: 0.498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgHQgLUZEZqx",
        "outputId": "8c7e7604-e96c-4614-e23f-b6ded0e9f8db"
      },
      "source": [
        "Convlstm2D_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49788638949394226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LChqUC9grBYo"
      },
      "source": [
        " # CNN-LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gKNnS1fTm4d"
      },
      "source": [
        "소스 코드 : https://colab.research.google.com/drive/1rIylR9RWEckndbyFNx1Wl_yUQZUF-wyI#scrollTo=M1QKFdJOYTjx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPjwlBM3JVI_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, ConvLSTM2D, Flatten\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ThbR1vuUdMF",
        "outputId": "1e300936-26e2-450e-fdd1-5bb6d4cf919d"
      },
      "source": [
        "inputs = keras.Input(shape=(2304, 3))\n",
        "x = inputs\n",
        "# 1차원 feature map 생성\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, padding=\"causal\", activation=\"relu\")(x)\n",
        "# LSTM\n",
        "x = layers.LSTM(16, activation='tanh')(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "outputs = x\n",
        "\n",
        "M10 = keras.Model(inputs, outputs)\n",
        "M10.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 2304, 3)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 2304, 32)          512       \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 16)                3136      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 3,937\n",
            "Trainable params: 3,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTgPc3LtT3B1",
        "outputId": "1881904a-8c70-4724-d7ff-afec668379f9"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_ = M10(x_batch)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_= M10(x_batch)\n",
        "        y_batch = y_batch.reshape(-1,1)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value)\n",
        "        val_acc_avg(acc_value)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "CNN_LSTM_loss = float(format(val_loss_avg.result()))\n",
        "CNN_LSTM_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69307 , Train acc: 0.50476\n",
            "Val_Loss: 0.694, Val_acc: 0.506\n",
            "Epoch 001: , Train Loss: 0.69366 , Train acc: 0.50379\n",
            "Val_Loss: 0.694, Val_acc: 0.501\n",
            "Epoch 002: , Train Loss: 0.69327 , Train acc: 0.50175\n",
            "Val_Loss: 0.693, Val_acc: 0.502\n",
            "Epoch 003: , Train Loss: 0.69328 , Train acc: 0.50215\n",
            "Val_Loss: 0.694, Val_acc: 0.502\n",
            "Epoch 004: , Train Loss: 0.69324 , Train acc: 0.50203\n",
            "Val_Loss: 0.694, Val_acc: 0.502\n",
            "Epoch 005: , Train Loss: 0.69364 , Train acc: 0.50222\n",
            "Val_Loss: 0.692, Val_acc: 0.503\n",
            "Epoch 006: , Train Loss: 0.69357 , Train acc: 0.50211\n",
            "Val_Loss: 0.693, Val_acc: 0.502\n",
            "Epoch 007: , Train Loss: 0.69320 , Train acc: 0.50244\n",
            "Val_Loss: 0.693, Val_acc: 0.502\n",
            "Epoch 008: , Train Loss: 0.69391 , Train acc: 0.50216\n",
            "Val_Loss: 0.692, Val_acc: 0.502\n",
            "Epoch 009: , Train Loss: 0.69405 , Train acc: 0.50119\n",
            "Val_Loss: 0.693, Val_acc: 0.501\n",
            "Epoch 010: , Train Loss: 0.69304 , Train acc: 0.50123\n",
            "Val_Loss: 0.693, Val_acc: 0.502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQoBcM6XW2A1",
        "outputId": "370463e4-b098-4569-d2b2-5606219b6eb2"
      },
      "source": [
        "CNN_LSTM_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5015603303909302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PROpLXbDVQ8L"
      },
      "source": [
        "# CNN-BLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lZGZh7-Ldf_"
      },
      "source": [
        "from random import random\n",
        "from numpy import array\n",
        "from numpy import cumsum\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "from random import random\n",
        "from numpy import array\n",
        "from numpy import cumsum\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg5UMArSX0Rd",
        "outputId": "df39040e-17e2-40c6-9d15-63677d9fce5c"
      },
      "source": [
        "inputs = keras.Input(shape=(2304, 3))\n",
        "x = inputs\n",
        "# 1차원 feature map 생성\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, padding=\"causal\", activation=\"relu\")(x)\n",
        "# LSTM\n",
        "x = layers.Bidirectional(LSTM(20, return_sequences=True))(x)\n",
        "x = layers.TimeDistributed(Dense(1, activation='sigmoid'))(x)\n",
        "outputs = x\n",
        "\n",
        "M11 = keras.Model(inputs, outputs)\n",
        "M11.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 2304, 3)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 2304, 32)          512       \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 2304, 40)          8480      \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 2304, 1)           41        \n",
            "=================================================================\n",
            "Total params: 9,033\n",
            "Trainable params: 9,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smqQhU_Le_WK",
        "outputId": "0ba82673-0b8c-475d-faf0-96399b9a5204"
      },
      "source": [
        "#정확도\n",
        "num_iters = train_len // batch_size\n",
        "num_epochs = 11\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "acc_fn = tf.keras.metrics.BinaryAccuracy()\n",
        "num_test_iters = num_iters // 4\n",
        "for epoch in range(num_epochs) :\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    val_acc_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for iter in range(num_iters) :\n",
        "        x_batch, y_batch = next(train_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_ = M11(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        epoch_loss_avg(loss_value)\n",
        "        epoch_acc_avg(acc_value)\n",
        "\n",
        "    for iter in range(num_test_iters) :\n",
        "        x_batch, y_batch = next(test_gen)\n",
        "        x_batch = x_batch.reshape(16, 2304, 3)\n",
        "        y_= M11(x_batch)\n",
        "        loss_value = loss_fn(y_batch, y_)\n",
        "        acc_value = acc_fn(y_batch, y_)\n",
        "        val_loss_avg(loss_value)\n",
        "        val_acc_avg(acc_value)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Epoch {:03d}: , Train Loss: {:.5f} , Train acc: {:.5f}\".format(epoch, epoch_loss_avg.result(), epoch_acc_avg.result()))\n",
        "    print(\"Val_Loss: {:.3f}, Val_acc: {:.3f}\".format(val_loss_avg.result(), val_acc_avg.result()))\n",
        "\n",
        "CNN_BLSTM_loss = float(format(val_loss_avg.result()))\n",
        "CNN_BLSTM_ACC = float(format(val_acc_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: , Train Loss: 0.69547 , Train acc: 0.49239\n",
            "Val_Loss: 0.698, Val_acc: 0.487\n",
            "Epoch 001: , Train Loss: 0.69431 , Train acc: 0.48830\n",
            "Val_Loss: 0.700, Val_acc: 0.490\n",
            "Epoch 002: , Train Loss: 0.69463 , Train acc: 0.48988\n",
            "Val_Loss: 0.696, Val_acc: 0.491\n",
            "Epoch 003: , Train Loss: 0.69557 , Train acc: 0.49004\n",
            "Val_Loss: 0.699, Val_acc: 0.489\n",
            "Epoch 004: , Train Loss: 0.69468 , Train acc: 0.48898\n",
            "Val_Loss: 0.695, Val_acc: 0.490\n",
            "Epoch 005: , Train Loss: 0.69452 , Train acc: 0.49087\n",
            "Val_Loss: 0.694, Val_acc: 0.492\n",
            "Epoch 006: , Train Loss: 0.69533 , Train acc: 0.49192\n",
            "Val_Loss: 0.695, Val_acc: 0.492\n",
            "Epoch 007: , Train Loss: 0.69501 , Train acc: 0.49194\n",
            "Val_Loss: 0.697, Val_acc: 0.492\n",
            "Epoch 008: , Train Loss: 0.69437 , Train acc: 0.49232\n",
            "Val_Loss: 0.697, Val_acc: 0.492\n",
            "Epoch 009: , Train Loss: 0.69479 , Train acc: 0.49212\n",
            "Val_Loss: 0.698, Val_acc: 0.492\n",
            "Epoch 010: , Train Loss: 0.69464 , Train acc: 0.49222\n",
            "Val_Loss: 0.698, Val_acc: 0.492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsvusoeNZxWM",
        "outputId": "742e594f-22b2-47af-ddfb-919e70842c38"
      },
      "source": [
        "CNN_BLSTM_ACC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49216732382774353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EiZgO6zUTiU"
      },
      "source": [
        "# Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "oF4uHYJ1s7P8",
        "outputId": "59d79ce5-d205-4bcb-c9cd-f010e0d7ee02"
      },
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['CNN','ANN', 'GRU', '1D CNN', 'LSTM', 'BLSTM', 'Convlstm2D', 'CNN-LSTM ','CNN-BLSTM'],\n",
        "    'Score': [CNN_ACC, ANN_ACC, GRU_ACC, CNN1D_ACC, LSTM_ACC, BLSTM_ACC, Convlstm2D_acc, CNN_LSTM_ACC, CNN_BLSTM_ACC]})\n",
        "models.sort_values (by='Score', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ANN</td>\n",
              "      <td>0.512090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BLSTM</td>\n",
              "      <td>0.508608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CNN-LSTM</td>\n",
              "      <td>0.501560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Convlstm2D</td>\n",
              "      <td>0.497886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1D CNN</td>\n",
              "      <td>0.495597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CNN-BLSTM</td>\n",
              "      <td>0.492167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>0.491069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>0.485658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRU</td>\n",
              "      <td>0.476878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Model     Score\n",
              "1         ANN  0.512090\n",
              "5       BLSTM  0.508608\n",
              "7   CNN-LSTM   0.501560\n",
              "6  Convlstm2D  0.497886\n",
              "3      1D CNN  0.495597\n",
              "8   CNN-BLSTM  0.492167\n",
              "4        LSTM  0.491069\n",
              "0         CNN  0.485658\n",
              "2         GRU  0.476878"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csuenHpw3l66"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}